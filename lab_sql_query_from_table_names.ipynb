{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "00a57394-53dd-47cd-a5e7-6e7122bbb0f6",
      "metadata": {
        "id": "00a57394-53dd-47cd-a5e7-6e7122bbb0f6"
      },
      "source": [
        "# SQL query from table names"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86bc2813-763c-49f2-9f5d-e1f87a20556f",
      "metadata": {
        "id": "86bc2813-763c-49f2-9f5d-e1f87a20556f"
      },
      "source": [
        "In This notebook we are going to test if using just the name of the table, and a shord definition of its contect we can use a model like GTP3.5-Turbo to select which tables are necessary to create a SQL Order to answer the user petition."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install OpenAI"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huvUva-eVQvv",
        "outputId": "46c491f2-93a0-44ae-b177-b7ce75d920bc"
      },
      "id": "huvUva-eVQvv",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: OpenAI in /usr/local/lib/python3.10/dist-packages (1.34.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from OpenAI) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from OpenAI) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from OpenAI) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from OpenAI) (2.7.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from OpenAI) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from OpenAI) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from OpenAI) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->OpenAI) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->OpenAI) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->OpenAI) (2024.6.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->OpenAI) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->OpenAI) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->OpenAI) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->OpenAI) (2.18.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "7fbbdf5b-4d7f-4496-8f40-9d15ea46d023",
      "metadata": {
        "id": "7fbbdf5b-4d7f-4496-8f40-9d15ea46d023"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "#import os\n",
        "#from dotenv import load_dotenv, find_dotenv\n",
        "#_ = load_dotenv(find_dotenv())\n",
        "from google.colab import userdata\n",
        "OPENAI_API_KEY  = userdata.get('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "e480bbfb-9a80-4ea6-b792-067e63ae3148",
      "metadata": {
        "id": "e480bbfb-9a80-4ea6-b792-067e63ae3148"
      },
      "outputs": [],
      "source": [
        "#Functio to call the model.\n",
        "def return_OAI(user_message):\n",
        "    client = OpenAI(\n",
        "    # This is the default and can be omitted\n",
        "    api_key=OPENAI_API_KEY,\n",
        ")\n",
        "    context = []\n",
        "    context.append({'role':'system', \"content\": user_message})\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=context,\n",
        "            temperature=0,\n",
        "        )\n",
        "\n",
        "    return (response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "6d5d2bdc-d822-4ed8-815e-b3f223730f15",
      "metadata": {
        "id": "6d5d2bdc-d822-4ed8-815e-b3f223730f15",
        "outputId": "238fe25b-ac87-41ab-e946-b2acff5ecd6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       table                                         definition\n",
            "0  employees  Employee information, name, department, contac...\n",
            "1     salary                       Salary details for each year\n",
            "2    studies  Educational studies, name of the institution, ...\n"
          ]
        }
      ],
      "source": [
        "#Definition of the tables.\n",
        "import pandas as pd\n",
        "\n",
        "# Table and definitions sample\n",
        "data = {\n",
        "    'table': ['employees', 'salary', 'studies'],\n",
        "    'definition': [\n",
        "        'Employee information, name, department, contact details',\n",
        "        'Salary details for each year',\n",
        "        'Educational studies, name of the institution, degrees'\n",
        "    ]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "009e681c-d95d-4c9c-b044-5bfd76e3ad95",
      "metadata": {
        "id": "009e681c-d95d-4c9c-b044-5bfd76e3ad95"
      },
      "outputs": [],
      "source": [
        "text_tables = '\\n'.join([f\"{row['table']}: {row['definition']}\" for index, row in df.iterrows()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "fe03ac25-8d02-4cd1-99a1-be4220c6fd2d",
      "metadata": {
        "id": "fe03ac25-8d02-4cd1-99a1-be4220c6fd2d",
        "outputId": "4b829098-27f2-4326-c32f-7fd280279530",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "employees: Employee information, name, department, contact details\n",
            "salary: Salary details for each year\n",
            "studies: Educational studies, name of the institution, degrees\n"
          ]
        }
      ],
      "source": [
        "print(text_tables)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "c7e275ae-f20d-4134-b9b6-d8677dfb544c",
      "metadata": {
        "id": "c7e275ae-f20d-4134-b9b6-d8677dfb544c"
      },
      "outputs": [],
      "source": [
        "prompt_question_tables = \"\"\"\n",
        "Given the following tables and their content definitions,\n",
        "###Tables\n",
        "{tables}\n",
        "\n",
        "Tell me which tables would be necessary to query with SQL to address the user's question below.\n",
        "Return the table names in a json format.\n",
        "###User Questyion:\n",
        "{question}\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "b1cb5957-2df2-4e5e-9e6a-ace955c9817e",
      "metadata": {
        "id": "b1cb5957-2df2-4e5e-9e6a-ace955c9817e"
      },
      "outputs": [],
      "source": [
        "#Creating the prompt, with the user questions and the tables definitions.\n",
        "pqt1 = prompt_question_tables.format(tables=text_tables, question = \"What are the salaries of the employees in the company?\")#ENTER YOUR QUERY HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "10d30f2b-6c23-4fd6-8038-840fba784cce",
      "metadata": {
        "id": "10d30f2b-6c23-4fd6-8038-840fba784cce",
        "outputId": "44e048ac-1f91-4980-b38e-0ad097a2fc44",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```json\n",
            "{\n",
            "    \"tables\": [\"employees\", \"salary\"]\n",
            "}\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "print(return_OAI(pqt1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "57e07083-be8f-4cd0-95bd-c4b909422c6b",
      "metadata": {
        "id": "57e07083-be8f-4cd0-95bd-c4b909422c6b"
      },
      "outputs": [],
      "source": [
        "pqt3 = prompt_question_tables.format(tables=text_tables,\n",
        "                                     question = \"What are the educational details of the employees?\")#ENTER YOUR QUERY HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "a0eeb79e-caf1-4f48-9897-168d95d2ae37",
      "metadata": {
        "id": "a0eeb79e-caf1-4f48-9897-168d95d2ae37",
        "outputId": "5e124c1d-36c5-48e7-907a-bbbfe3014a53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```json\n",
            "{\n",
            "    \"tables\": [\"employees\", \"studies\"]\n",
            "}\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "print(return_OAI(pqt3))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "321bb9a2-4937-4e9a-a31b-7049cb8f5aa3",
      "metadata": {
        "id": "321bb9a2-4937-4e9a-a31b-7049cb8f5aa3"
      },
      "source": [
        "# Exercise\n",
        " - Complete the prompts similar to what we did in class.\n",
        "     - Try a few versions if you have time\n",
        "     - Be creative\n",
        " - Write a one page report summarizing your findings.\n",
        "     - Were there variations that didn't work well? i.e., where GPT either hallucinated or wrong\n",
        " - What did you learn?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pqt4 = prompt_question_tables.format(\n",
        "    tables=text_tables,\n",
        "    question=\"What are the salaries and educational details of employees?\"\n",
        ")\n",
        "print(return_OAI(pqt4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtYILhacYRQr",
        "outputId": "9a35ce61-3d74-4640-d08b-47bd70afb7ab"
      },
      "id": "EtYILhacYRQr",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```json\n",
            "{\n",
            "    \"tables\": [\"employees\", \"salary\", \"studies\"]\n",
            "}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pqt5 = prompt_question_tables.format(\n",
        "    tables=text_tables,\n",
        "    question=\"Which tables should I query to get a report on employee performance and compensation?\"\n",
        ")\n",
        "print(return_OAI(pqt5))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUspwqlnYofX",
        "outputId": "785b85ff-218f-4dce-9c8a-b5ff3b88df4c"
      },
      "id": "YUspwqlnYofX",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```json\n",
            "{\n",
            "    \"tables\": [\"employees\", \"salary\"]\n",
            "}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pqt6 = prompt_question_tables.format(\n",
        "    tables=text_tables,\n",
        "    question=\"I need to generate a report on the educational background and work history of our employees.\"\n",
        ")\n",
        "print(return_OAI(pqt6))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMGcFdshYxlb",
        "outputId": "d00f2930-86e0-4f9a-f89f-425721631a18"
      },
      "id": "UMGcFdshYxlb",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```json\n",
            "{\n",
            "    \"tables\": [\"employees\", \"studies\"]\n",
            "}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary:"
      ],
      "metadata": {
        "id": "F6Kd7RIDZnnI"
      },
      "id": "F6Kd7RIDZnnI"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   The GPT-3.5-Turbo model exhibited a strong capability to comprehend the user's questions.\n",
        "*   The model adeptly identified the necessary database tables to address the user's requests.\n",
        "*   Whether the questions involved employee salaries, educational details, or comprehensive reports, the model consistently selected the appropriate combination of tables.\n",
        "*   The model's ability to bridge the gap between natural language and database schemas was particularly impressive.\n",
        "*   The model could translate the user's questions into the relevant SQL queries without requiring detailed knowledge of the underlying data structure.\n",
        "\n",
        "*   This suggests that using a large language model like GPT-3.5-Turbo can be an effective approach for generating SQL queries from user requests, making data-driven tasks more accessible to a wider audience.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "w5A0bSbtZyXr"
      },
      "id": "w5A0bSbtZyXr"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}